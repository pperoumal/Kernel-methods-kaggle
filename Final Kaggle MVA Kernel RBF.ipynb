{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet du cours \"Kernel methods\" du master MVA\n",
    "Le projet de ce cours consiste en la classification d'images. Dans ce notebook, on implémente de manière la plus détaillée et la plus claire possible l'ensemble des classes et fonctions des algorithmes que nous utilisons.    \n",
    "\n",
    "Ce projet se fera en 3 étapes :\n",
    "- Preprocessing des données\n",
    "- Feature extraction\n",
    "- Prediction par SVM\n",
    "\n",
    "Il est indiqué dans l'énoncé que l'étape de preprocessing a déjà été réalisée. Nous allons donc directement procéder à l'extraction de nos features (par HOG) et à la prédiction de la nature de nos images (par SVM).\n",
    "\n",
    "Ce notebook utilise comme kernel le RBF kernel qui est celui qui donne les meilleurs résultats. Pour voir les résultats avec d'autres kernels, se reporter aux notebooks joints (moins détaillés mais présentant les principaux résultats)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas\n",
    "import cvxopt\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "from scipy.stats import mode\n",
    "from scipy.linalg import eigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données\n",
    "\n",
    "On importe les données du concours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train=pandas.read_csv('/Users/badr-eddinecherief-abdellatif/Documents/ENSAE/3A/MVA/Kernel methods/Projet ENS/Bases/Xtr.csv',header=None,sep=',')\n",
    "df_train=df_train.drop(3072,1)\n",
    "df_test=pandas.read_csv('/Users/badr-eddinecherief-abdellatif/Documents/ENSAE/3A/MVA/Kernel methods/Projet ENS/Bases/Xte.csv',header=None,sep=',')\n",
    "df_test=df_test.drop(3072,1)\n",
    "y_train=pandas.read_csv('/Users/badr-eddinecherief-abdellatif/Documents/ENSAE/3A/MVA/Kernel methods/Projet ENS/Bases/Ytr.csv',sep=';')\n",
    "y_train=pandas.DataFrame(y_train['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.genfromtxt('/Users/badr-eddinecherief-abdellatif/Documents/ENSAE/3A/MVA/Kernel methods/Projet ENS/Bases/Xtr.csv',delimiter=',')[:,0:3072]\n",
    "Y_train = np.genfromtxt('/Users/badr-eddinecherief-abdellatif/Documents/ENSAE/3A/MVA/Kernel methods/Projet ENS/Bases/Ytr.csv',delimiter=';')[1:5001,1]\n",
    "X_test = np.genfromtxt('/Users/badr-eddinecherief-abdellatif/Documents/ENSAE/3A/MVA/Kernel methods/Projet ENS/Bases/Xte.csv',delimiter=',')[:,0:3072]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Répartition des labels\n",
    "Nous travaillons sur un échantillon d'apprentissage dans le but de classifier des images. Vérifions que nous avons bien équirépartition des images dans l'échantillon d'apprentissage afin de pouvoir mener à bien notre modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    500\n",
       "3    500\n",
       "6    500\n",
       "2    500\n",
       "9    500\n",
       "5    500\n",
       "1    500\n",
       "8    500\n",
       "4    500\n",
       "0    500\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation des méthodes\n",
    "\n",
    "Dans cette partie, nous implémenterons les différentes méthodes que nous testerons par la suite. Il s'agit des méthodes suivantes:\n",
    "- SVM\n",
    "- ACP\n",
    "- HOG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVMTrainer(object):\n",
    "    def __init__(self, c, sigma):\n",
    "        self._c = c\n",
    "        self.sigma=sigma\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        lagrange_multipliers = self._compute_multipliers(X, y)\n",
    "        return self._construct_predictor(X, y, lagrange_multipliers)\n",
    "\n",
    "    def _gram_matrix(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        v=norm(X,2,axis=1)**2\n",
    "        v2=array([v,]*n_samples)+array([v,]*n_samples).transpose()-2*dot(X.values,transpose(X.values))\n",
    "        K=exp(-v2/(2*(self.sigma)**2)) #utilisation de la définition de la norme deux pour une implémentation simple\n",
    "        print(\"Taille de la matrice de Gram :\",K.shape)\n",
    "        return K\n",
    "\n",
    "    def _construct_predictor(self, X, y, lagrange_multipliers):\n",
    "        support_vector_indices=abs(lagrange_multipliers)>0\n",
    "        support_multipliers = lagrange_multipliers[support_vector_indices] # alpha i positifs\n",
    "        support_vectors = X[support_vector_indices] # vecteurs support\n",
    "        support_vector_labels = y[support_vector_indices] # labels des vecteurs support\n",
    "        print(\"Nombre de vecteurs supports :\",len(support_vectors))\n",
    "        pre=SVMPredictor(sigma=self.sigma,bias=0.0,weights=support_multipliers,\n",
    "             support_vectors=support_vectors,support_vector_labels=support_vector_labels).predictest(support_vectors.values)[0]\n",
    "        bias = np.mean(support_vector_labels[:,0]-pre)\n",
    "        print(\"Biais:\",bias)\n",
    "        return SVMPredictor(sigma=self.sigma,bias=bias,weights=support_multipliers,support_vectors=support_vectors,\n",
    "            support_vector_labels=support_vector_labels)\n",
    "\n",
    "    def _compute_multipliers(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        K=self._gram_matrix(X)\n",
    "        P=cvxopt.matrix(K)\n",
    "        q=cvxopt.matrix(-1*y[:,0])\n",
    "        G_std=cvxopt.matrix(-1*np.diag(y[:,0]))\n",
    "        h_std=cvxopt.matrix(np.zeros(n_samples))\n",
    "        G_slack=cvxopt.matrix(np.diag(y[:,0]))\n",
    "        h_slack=cvxopt.matrix(np.ones(n_samples) * self._c)\n",
    "        G=cvxopt.matrix(np.vstack((G_std, G_slack)))\n",
    "        h=cvxopt.matrix(np.vstack((h_std, h_slack)))\n",
    "        A=cvxopt.matrix(np.ones(n_samples),(1,n_samples))\n",
    "        b=cvxopt.matrix(0.0)\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A=None, b=None)\n",
    "        return np.ravel(solution['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVMPredictor(object):\n",
    "    def __init__(self,sigma,bias,weights,support_vectors,support_vector_labels):\n",
    "        self.sigma=sigma\n",
    "        self._bias = bias\n",
    "        self._weights = weights\n",
    "        self._support_vectors = support_vectors\n",
    "        self._support_vector_labels = support_vector_labels\n",
    "\n",
    "    def predictest(self,x):\n",
    "        v = array([norm(x,2,axis=1)**2,]*len(self._support_vectors))\n",
    "        inter = array([norm(self._support_vectors,2,axis=1)**2,]*len(x)).transpose() + v\n",
    "        inter1 = inter - 2*dot(self._support_vectors,transpose(x))\n",
    "        inter2 = exp(-asarray(inter1)/(2*(self.sigma)**2))\n",
    "        result = dot(transpose(self._weights),inter2)+self._bias\n",
    "        return sign(result),result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation du SVM au cas multi-classe\n",
    "On va tout d'abord implémenter la méthode One Vs One, i.e. considérer 10x9/2=45 problèmes de classifications binaires en traitant des paires d'instances, puis implémenter la méthode One Vs Rest, i.e. entraîner un classifieur par classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Vs One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVMOvO(data_train,data_test,is_train,C,sigma):\n",
    "    SVM=SVMTrainer(C,sigma)\n",
    "    result=(20*ones(len(data_test))).reshape(len(data_test),1)\n",
    "    for i in [0,1,2,3,4,5,6,7,8]:\n",
    "        for j in range(i+1,10):\n",
    "            print(\"Classe :\",i,j)\n",
    "            df_train_ij=data_train[asmatrix(is_train,dtype=ndarray)==(i,j)].copy()\n",
    "            is_train_ij=is_train[asmatrix(is_train,dtype=ndarray)==(i,j)].copy()\n",
    "            is_train_ij[is_train==i]=1\n",
    "            is_train_ij[is_train==j]=-1\n",
    "            s1=time.clock()\n",
    "            SVMPred=SVM.train(df_train_ij,asfarray(is_train_ij))\n",
    "            s2=time.clock()\n",
    "            print(\"Temps pour l'entrainement :\",s2-s1)\n",
    "            s3=time.clock()\n",
    "            values=SVMPred.predictest(data_test.values)[0]\n",
    "            s4=time.clock()\n",
    "            print(\"Temps pour la prédiction :\",s4-s3)\n",
    "            values[values==1]=i\n",
    "            values[values==-1]=j\n",
    "            values=values.reshape(len(data_test),1)\n",
    "            result=concatenate((result,values),1)\n",
    "            is_test_predict=mode(result,axis=1)\n",
    "    return(is_test_predict)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Vs Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVMOvR(data_train,data_test,is_train,C,sigma):\n",
    "    SVM=SVMTrainer(C,sigma)\n",
    "    result=(-20*ones(len(data_test))).reshape(len(data_test),1)\n",
    "    for i in [0,1,2,3,4,5,6,7,8,9]:\n",
    "        print(\"Classe :\",i)\n",
    "        is_train_i=is_train.copy()\n",
    "        is_train_i[is_train==i]=1\n",
    "        is_train_i[is_train!=i]=-1\n",
    "        s1=time.clock()\n",
    "        SVMPred=SVM.train(data_train,asfarray(is_train_i))\n",
    "        s2=time.clock()\n",
    "        print(\"Temps pour l'entrainement :\",s2-s1)\n",
    "        s3=time.clock()\n",
    "        values=SVMPred.predictest(data_test.values)[1]\n",
    "        s4=time.clock()\n",
    "        print(\"Temps pour la prédiction :\",s4-s3)\n",
    "        values=values.reshape(len(data_test),1)\n",
    "        result=concatenate((result,values),1)\n",
    "    predict=argmax(result,axis=1)-1\n",
    "    return(predict)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel - Analyse en Composantes Principales\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kpca(X, sigma, n_components):\n",
    "\n",
    "    # Gram matrix \n",
    "    n_samples, n_features = X.shape\n",
    "    v=norm(X,2,axis=1)**2\n",
    "    v2=array([v,]*n_samples)+array([v,]*n_samples).transpose()-2*dot(X.values,transpose(X.values))\n",
    "    K=exp(-v2/(2*sigma**2))\n",
    "    \n",
    "    # Center \n",
    "    N = K.shape[0]\n",
    "    one_n = np.ones((N,N)) / N\n",
    "    K = K - one_n.dot(K) - K.dot(one_n) + one_n.dot(K).dot(one_n)\n",
    "\n",
    "    # Eigenvalues in descending order with corresponding eigenvectors \n",
    "    eigvals, eigvecs = eigh(K)\n",
    "\n",
    "    # Eigenvectors that corresponds to the highest eigenvalues.\n",
    "    X_kpca = np.column_stack((eigvecs[:,-i] for i in range(1,n_components+1)))\n",
    "\n",
    "    return X_kpca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOG\n",
    "\n",
    "Implémentation de la méthode d'extraction de features inspirée de l'article https://hal.inria.fr/inria-00548512/document de N. Dalal et B. Triggs et du site http://www.learnopencv.com/histogram-of-oriented-gradients/. On choisit de diviser l'image de 32 pixels en 4 cellules de (8,8) pixels chacun, en normalisant par blocs de 4 cellules, ce qui donne une base X de taille 3 (nombre de blocs sur l'axe x) fois 3 (nombre de blocs sur l'axe y) fois 9 (taille d'un histogramme) fois 4 (nombre d'histogrammes par bloc, un histogramme correspondant à une cellule) fois 3 (pour les différentes couleurs de l'image), i.e. on obtient une base X avec 972 variables au lieu de 3072."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HOG :\n",
    "\n",
    "    def __init__(self, nbins=9):\n",
    "        self.nbins = nbins\n",
    "\n",
    "    def _calc_gradient_discret(self, img):\n",
    "        n_x, n_y = img.shape\n",
    "        histogram = numpy.zeros((4, 4, self.nbins))\n",
    "\n",
    "        for i in range(0, n_x) :\n",
    "            for j in range(0, n_y) :\n",
    "                dx = 0\n",
    "                dy = 0\n",
    "                if i < n_x - 1 :\n",
    "                    dx += img[i + 1, j]\n",
    "                if i > 0 :\n",
    "                    dx -= img[i - 1, j]\n",
    "                if j < n_y - 1 :\n",
    "                    dy += img[i, j + 1]\n",
    "                if j > 0 :\n",
    "                    dy -= img[i, j - 1]\n",
    "\n",
    "                if dy == 0 and dx == 0 :\n",
    "                    continue\n",
    "\n",
    "                magnitude = numpy.sqrt(dx**2 + dy**2)\n",
    "                if dx == 0 :\n",
    "                    angle = numpy.pi / 2\n",
    "                else:\n",
    "                    angle = numpy.arctan(dy / dx)\n",
    "                    angle = (angle + numpy.pi / 2) / (numpy.pi / self.nbins)\n",
    "               \n",
    "                bin_pos = int(numpy.floor(angle))\n",
    "\n",
    "                if bin_pos == self.nbins :\n",
    "                    bin_pos = 0\n",
    "                    angle = 0\n",
    "\n",
    "                closest_bin = bin_pos\n",
    "\n",
    "                if bin_pos == 0 :\n",
    "                    if angle < 0.5 :\n",
    "                        second_closest_bin = self.nbins - 1\n",
    "                    else:\n",
    "                        second_closest_bin = 1\n",
    "                elif bin_pos == self.nbins - 1 :\n",
    "                    if angle < self.nbins - 0.5 :\n",
    "                        second_closest_bin = self.nbins - 2\n",
    "                    else:\n",
    "                        second_closest_bin = 0\n",
    "                else:\n",
    "                    if angle < bin_pos + 0.5 :\n",
    "                        second_closest_bin = bin_pos - 1\n",
    "                    else:\n",
    "                        second_closest_bin = bin_pos + 1\n",
    "\n",
    "                if angle < bin_pos + 0.5 :\n",
    "                    second_closest_bin_distance = angle - (bin_pos - 0.5)\n",
    "                else:\n",
    "                    second_closest_bin_distance = (bin_pos + 1.5) - angle\n",
    "\n",
    "                r = second_closest_bin_distance\n",
    "                histogram[i / 8, j / 8, closest_bin] += r * magnitude\n",
    "                histogram[i / 8, j / 8, second_closest_bin] += (1 - r) * magnitude\n",
    "\n",
    "        vec = numpy.zeros((3, 3, self.nbins * 4))\n",
    "\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                aux = histogram[i:i + 2, j:j + 2, :].flatten().copy()\n",
    "                aux = aux / numpy.linalg.norm(aux)\n",
    "                vec[i, j, :] = aux\n",
    "\n",
    "        return vec.flatten()\n",
    "\n",
    "    \n",
    "    def _calc_gradient_one_image(self, img):\n",
    "        nchannels = img.shape[2]\n",
    "        vec = []\n",
    "\n",
    "        for i in range(nchannels):\n",
    "            vec.append(self._calc_gradient_discret(img[:,:,i]))\n",
    "\n",
    "        return numpy.array(vec).flatten()\n",
    "\n",
    "    \n",
    "    def hog(self, X):\n",
    "        n = X.shape[0]\n",
    "        X_new = []\n",
    "\n",
    "        for i in range(n):\n",
    "            X_new.append(self._calc_gradient_one_image(X[i,:,:,:]))\n",
    "\n",
    "        return numpy.array(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "Afin de tester nos modèles sur nos données d'entraînement, on va découper notre base d'entraînement en train/test à hauteur de 60/40%.\n",
    "\n",
    "Pour plus de clarté, on ne présente ici que les modèles optimaux pour chacune des étapes suivantes (avant HOG, après ACP, après HOG, après HOG+ACP), i.e. la méthode optimale avec les paramètres optimaux parmi un nombre fini de modèles (les 2 paramètres variant de 1 à 10). Pour s'en assurer, il suffit de faire varier les paramètres à chaque fois (par une simple boucle sur ces paramètres)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avant HOG : SVM One Vs Rest (C=6,sigma=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3072)\n",
      "(2000, 3072)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    311\n",
       "1    308\n",
       "0    306\n",
       "6    305\n",
       "8    304\n",
       "4    298\n",
       "5    294\n",
       "7    292\n",
       "9    291\n",
       "2    291\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1 = df_train[0:3000]\n",
    "X_test_1 = df_train[3000:5000]\n",
    "Y_train_1 = y_train[0:3000]\n",
    "Y_test_1 = y_train[3000:5000]\n",
    "print(X_train_1.shape)\n",
    "print(X_test_1.shape)\n",
    "Y_train_1[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe : 0\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1141e+03 -5.4312e+04  1e+05  4e-01  2e-14\n",
      " 1: -9.3079e+02 -1.0934e+04  1e+04  2e-16  2e-14\n",
      " 2: -1.2907e+03 -4.2159e+03  3e+03  2e-16  2e-14\n",
      " 3: -1.4542e+03 -2.4599e+03  1e+03  1e-16  3e-14\n",
      " 4: -1.5245e+03 -1.7928e+03  3e+02  2e-16  3e-14\n",
      " 5: -1.5499e+03 -1.6173e+03  7e+01  2e-16  3e-14\n",
      " 6: -1.5575e+03 -1.5642e+03  7e+00  2e-16  3e-14\n",
      " 7: -1.5588e+03 -1.5591e+03  4e-01  2e-16  3e-14\n",
      " 8: -1.5588e+03 -1.5589e+03  1e-02  2e-16  3e-14\n",
      " 9: -1.5589e+03 -1.5589e+03  4e-04  2e-16  3e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.00733333333333\n",
      "Temps pour l'entrainement : 58.527278\n",
      "Temps pour la prédiction : 2.6031779999999998\n",
      "Classe : 1\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.1956e+02 -5.6036e+04  1e+05  5e-01  2e-14\n",
      " 1: -1.4963e+02 -1.1295e+04  1e+04  2e-16  3e-14\n",
      " 2: -6.3763e+02 -3.6711e+03  3e+03  2e-16  3e-14\n",
      " 3: -8.5230e+02 -1.6205e+03  8e+02  2e-16  3e-14\n",
      " 4: -9.1344e+02 -1.1139e+03  2e+02  2e-16  2e-14\n",
      " 5: -9.3679e+02 -9.7919e+02  4e+01  2e-16  2e-14\n",
      " 6: -9.4338e+02 -9.4869e+02  5e+00  2e-16  2e-14\n",
      " 7: -9.4457e+02 -9.4485e+02  3e-01  2e-16  2e-14\n",
      " 8: -9.4466e+02 -9.4466e+02  8e-03  2e-16  2e-14\n",
      " 9: -9.4466e+02 -9.4466e+02  2e-04  2e-16  2e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.000666666666667\n",
      "Temps pour l'entrainement : 56.39386399999999\n",
      "Temps pour la prédiction : 2.973040000000026\n",
      "Classe : 2\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1390e+03 -5.2301e+04  1e+05  4e-01  4e-14\n",
      " 1: -9.9945e+02 -1.0393e+04  9e+03  2e-16  5e-14\n",
      " 2: -1.2820e+03 -3.8993e+03  3e+03  1e-16  5e-14\n",
      " 3: -1.4505e+03 -2.2013e+03  8e+02  2e-16  4e-14\n",
      " 4: -1.5142e+03 -1.6932e+03  2e+02  2e-16  4e-14\n",
      " 5: -1.5342e+03 -1.5665e+03  3e+01  2e-16  4e-14\n",
      " 6: -1.5391e+03 -1.5432e+03  4e+00  2e-16  4e-14\n",
      " 7: -1.5400e+03 -1.5402e+03  2e-01  2e-16  4e-14\n",
      " 8: -1.5400e+03 -1.5400e+03  7e-03  2e-16  4e-14\n",
      " 9: -1.5400e+03 -1.5400e+03  2e-04  2e-16  4e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.00333333333333\n",
      "Temps pour l'entrainement : 60.445492\n",
      "Temps pour la prédiction : 2.724302000000023\n",
      "Classe : 3\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1892e+03 -5.1179e+04  9e+04  4e-01  3e-14\n",
      " 1: -1.0509e+03 -9.9338e+03  9e+03  2e-16  3e-14\n",
      " 2: -1.3356e+03 -3.5621e+03  2e+03  1e-16  3e-14\n",
      " 3: -1.4946e+03 -2.1505e+03  7e+02  2e-16  3e-14\n",
      " 4: -1.5468e+03 -1.7439e+03  2e+02  2e-16  3e-14\n",
      " 5: -1.5667e+03 -1.5953e+03  3e+01  2e-16  3e-14\n",
      " 6: -1.5711e+03 -1.5735e+03  2e+00  2e-16  3e-14\n",
      " 7: -1.5716e+03 -1.5718e+03  1e-01  2e-16  3e-14\n",
      " 8: -1.5717e+03 -1.5717e+03  4e-03  2e-16  3e-14\n",
      " 9: -1.5717e+03 -1.5717e+03  2e-04  2e-16  3e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.002\n",
      "Temps pour l'entrainement : 54.25525099999999\n",
      "Temps pour la prédiction : 2.6037299999999846\n",
      "Classe : 4\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1089e+03 -5.5002e+04  1e+05  4e-01  3e-14\n",
      " 1: -9.3677e+02 -1.1397e+04  1e+04  2e-16  3e-14\n",
      " 2: -1.2604e+03 -3.7835e+03  3e+03  2e-16  3e-14\n",
      " 3: -1.4331e+03 -2.1296e+03  7e+02  2e-16  3e-14\n",
      " 4: -1.4924e+03 -1.7708e+03  3e+02  2e-16  3e-14\n",
      " 5: -1.5135e+03 -1.5674e+03  5e+01  1e-16  3e-14\n",
      " 6: -1.5203e+03 -1.5254e+03  5e+00  2e-16  3e-14\n",
      " 7: -1.5212e+03 -1.5215e+03  2e-01  2e-16  3e-14\n",
      " 8: -1.5213e+03 -1.5213e+03  6e-03  2e-16  3e-14\n",
      " 9: -1.5213e+03 -1.5213e+03  2e-04  2e-16  3e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.00133333333333\n",
      "Temps pour l'entrainement : 58.76074\n",
      "Temps pour la prédiction : 2.274310000000014\n",
      "Classe : 5\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.4163e+02 -5.6012e+04  1e+05  5e-01  3e-14\n",
      " 1: -7.1326e+02 -1.1980e+04  1e+04  2e-16  4e-14\n",
      " 2: -1.0478e+03 -4.0408e+03  3e+03  2e-16  4e-14\n",
      " 3: -1.2249e+03 -2.1087e+03  9e+02  2e-16  4e-14\n",
      " 4: -1.2895e+03 -1.5516e+03  3e+02  2e-16  4e-14\n",
      " 5: -1.3137e+03 -1.3698e+03  6e+01  2e-16  4e-14\n",
      " 6: -1.3213e+03 -1.3280e+03  7e+00  2e-16  4e-14\n",
      " 7: -1.3226e+03 -1.3230e+03  4e-01  2e-16  4e-14\n",
      " 8: -1.3227e+03 -1.3228e+03  1e-02  2e-16  4e-14\n",
      " 9: -1.3227e+03 -1.3227e+03  4e-04  2e-16  4e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.00133333333333\n",
      "Temps pour l'entrainement : 50.37665799999996\n",
      "Temps pour la prédiction : 2.150374999999997\n",
      "Classe : 6\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.7881e+02 -5.4134e+04  1e+05  4e-01  4e-14\n",
      " 1: -6.8492e+02 -1.0943e+04  1e+04  2e-16  5e-14\n",
      " 2: -1.0209e+03 -3.5801e+03  3e+03  2e-16  4e-14\n",
      " 3: -1.1910e+03 -1.9929e+03  8e+02  2e-16  4e-14\n",
      " 4: -1.2575e+03 -1.4545e+03  2e+02  2e-16  4e-14\n",
      " 5: -1.2789e+03 -1.3360e+03  6e+01  1e-16  4e-14\n",
      " 6: -1.2852e+03 -1.2937e+03  9e+00  2e-16  3e-14\n",
      " 7: -1.2865e+03 -1.2871e+03  6e-01  2e-16  4e-14\n",
      " 8: -1.2866e+03 -1.2866e+03  2e-02  2e-16  4e-14\n",
      " 9: -1.2866e+03 -1.2866e+03  5e-04  2e-16  4e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.00133333333333\n",
      "Temps pour l'entrainement : 50.32547499999998\n",
      "Temps pour la prédiction : 2.5405079999999884\n",
      "Classe : 7\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.5738e+02 -5.2871e+04  1e+05  4e-01  3e-14\n",
      " 1: -5.1292e+02 -1.0399e+04  1e+04  2e-16  3e-14\n",
      " 2: -8.9293e+02 -3.3859e+03  2e+03  2e-16  3e-14\n",
      " 3: -1.0600e+03 -1.8329e+03  8e+02  2e-16  3e-14\n",
      " 4: -1.1244e+03 -1.3150e+03  2e+02  2e-16  3e-14\n",
      " 5: -1.1478e+03 -1.1826e+03  3e+01  2e-16  3e-14\n",
      " 6: -1.1540e+03 -1.1587e+03  5e+00  2e-16  3e-14\n",
      " 7: -1.1551e+03 -1.1555e+03  3e-01  2e-16  3e-14\n",
      " 8: -1.1552e+03 -1.1553e+03  1e-02  2e-16  3e-14\n",
      " 9: -1.1552e+03 -1.1552e+03  4e-04  2e-16  3e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.002\n",
      "Temps pour l'entrainement : 50.22770799999995\n",
      "Temps pour la prédiction : 2.161548000000039\n",
      "Classe : 8\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1373e+03 -5.2162e+04  1e+05  4e-01  3e-14\n",
      " 1: -1.0056e+03 -1.0231e+04  9e+03  2e-16  4e-14\n",
      " 2: -1.3192e+03 -3.8237e+03  3e+03  2e-16  4e-14\n",
      " 3: -1.4808e+03 -2.2605e+03  8e+02  2e-16  4e-14\n",
      " 4: -1.5464e+03 -1.7209e+03  2e+02  2e-16  4e-14\n",
      " 5: -1.5654e+03 -1.5943e+03  3e+01  2e-16  4e-14\n",
      " 6: -1.5700e+03 -1.5724e+03  2e+00  2e-16  4e-14\n",
      " 7: -1.5705e+03 -1.5706e+03  1e-01  2e-16  4e-14\n",
      " 8: -1.5705e+03 -1.5705e+03  4e-03  2e-16  4e-14\n",
      " 9: -1.5705e+03 -1.5705e+03  2e-04  2e-16  4e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.00733333333333\n",
      "Temps pour l'entrainement : 50.474189000000024\n",
      "Temps pour la prédiction : 2.175991999999951\n",
      "Classe : 9\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.0148e+02 -5.7491e+04  1e+05  5e-01  2e-14\n",
      " 1: -2.5836e+02 -1.2704e+04  1e+04  8e-03  2e-14\n",
      " 2: -6.5254e+02 -3.6671e+03  3e+03  2e-03  2e-14\n",
      " 3: -8.6699e+02 -1.6696e+03  8e+02  2e-04  2e-14\n",
      " 4: -9.3311e+02 -1.1255e+03  2e+02  2e-05  2e-14\n",
      " 5: -9.5678e+02 -9.9745e+02  4e+01  2e-06  2e-14\n",
      " 6: -9.6374e+02 -9.6902e+02  5e+00  1e-07  2e-14\n",
      " 7: -9.6499e+02 -9.6531e+02  3e-01  6e-09  2e-14\n",
      " 8: -9.6509e+02 -9.6510e+02  1e-02  1e-10  2e-14\n",
      " 9: -9.6509e+02 -9.6509e+02  4e-04  2e-12  2e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.0\n",
      "Temps pour l'entrainement : 49.97371799999996\n",
      "Temps pour la prédiction : 2.1899349999999913\n"
     ]
    }
   ],
   "source": [
    "y_predict_OvR=SVMOvR(X_train_1,X_test_1,Y_train_1,6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de bonnes prédictions : 0.207\n"
     ]
    }
   ],
   "source": [
    "compt=Y_test_1.values[:,0]-y_predict_OvR\n",
    "print(\"Pourcentage de bonnes prédictions :\",sum(compt==0)/len(Y_test_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Après ACP : SVM One Vs Rest (C=6,sigma=2, 30 composantes conservées) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3072)\n",
      "(2000, 3072)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    311\n",
       "1    308\n",
       "0    306\n",
       "6    305\n",
       "8    304\n",
       "4    298\n",
       "5    294\n",
       "7    292\n",
       "9    291\n",
       "2    291\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_kacp = pandas.DataFrame(kpca(df_train,2,30))[0:3000]\n",
    "X_test_kacp = pandas.DataFrame(kpca(df_train,2,30))[3000:5000]\n",
    "Y_train_1 = y_train[0:3000]\n",
    "Y_test_1 = y_train[3000:5000]\n",
    "print(X_train_1.shape)\n",
    "print(X_test_1.shape)\n",
    "Y_train_1[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe : 0\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8069e+03 -4.7301e+04  8e+04  3e-01  7e-14\n",
      " 1: -3.5143e+03 -1.0779e+04  7e+03  2e-16  9e-14\n",
      " 2: -3.5976e+03 -4.0723e+03  5e+02  2e-16  8e-14\n",
      " 3: -3.6332e+03 -3.9621e+03  3e+02  1e-16  7e-14\n",
      " 4: -3.6558e+03 -3.8455e+03  2e+02  2e-16  7e-14\n",
      " 5: -3.6708e+03 -3.6920e+03  2e+01  2e-16  8e-14\n",
      " 6: -3.6720e+03 -3.6779e+03  6e+00  1e-16  7e-14\n",
      " 7: -3.6721e+03 -3.6775e+03  5e+00  2e-16  7e-14\n",
      " 8: -3.6723e+03 -3.6763e+03  4e+00  2e-16  7e-14\n",
      " 9: -3.6725e+03 -3.6756e+03  3e+00  2e-16  7e-14\n",
      "10: -3.6726e+03 -3.6750e+03  2e+00  2e-16  7e-14\n",
      "11: -3.6728e+03 -3.6746e+03  2e+00  2e-16  8e-14\n",
      "12: -3.6729e+03 -3.6743e+03  1e+00  2e-16  9e-14\n",
      "13: -3.6730e+03 -3.6740e+03  1e+00  2e-16  9e-14\n",
      "14: -3.6731e+03 -3.6737e+03  6e-01  2e-16  1e-13\n",
      "15: -3.6732e+03 -3.6735e+03  4e-01  2e-16  1e-13\n",
      "16: -3.6732e+03 -3.6734e+03  2e-01  2e-16  1e-13\n",
      "17: -3.6733e+03 -3.6733e+03  8e-02  2e-16  1e-13\n"
     ]
    }
   ],
   "source": [
    "y_predict_OvR=SVMOvR(X_train_kacp,X_test_kacp,Y_train_1,6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compt=Y_test_1.values[:,0]-y_predict_OvR\n",
    "print(\"Pourcentage de bonnes prédictions :\",sum(compt==0)/len(Y_test_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Après HOG :  SVM One Vs Rest (C=6, sigma=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Création de la nouvelle base X obtenue après extraction de features\n",
    "\n",
    "Xtrain = numpy.reshape(X_train, (X_train.shape[0], 3, 32, 32))\n",
    "Xtrain = numpy.swapaxes(Xtrain, 1, 2)\n",
    "Xtrain = numpy.swapaxes(Xtrain, 2, 3)\n",
    "\n",
    "Xtest = numpy.reshape(X_test, (X_test.shape[0], 3, 32, 32))\n",
    "Xtest = numpy.swapaxes(Xtest, 1, 2)\n",
    "Xtest = numpy.swapaxes(Xtest, 2, 3)\n",
    "\n",
    "histogram=HOG(nbins=9)\n",
    "h=histogram.hog(Xtrain)\n",
    "g=histogram.hog(Xtest)\n",
    "\n",
    "X_tr = pandas.DataFrame(h)\n",
    "X_te = pandas.DataFrame(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_2 = X_tr[0:3000]\n",
    "X_test_2 = X_tr[3000:5000]\n",
    "Y_train_2 = y_train[0:3000]\n",
    "Y_test_2 = y_train[3000:5000]\n",
    "print(X_train_2.shape)\n",
    "print(X_test_2.shape)\n",
    "Y_train_2[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict_OvR=SVMOvR(X_train_2,X_test_2,Y_train_2,6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compt=Y_test_2.values[:,0]-y_predict_OvR\n",
    "print(\"Pourcentage de bonnes prédictions :\",sum(compt==0)/len(Y_test_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Après HOG + ACP :  SVM One Vs Rest (C=6, sigma=2, 30 composantes conservées) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_3 = pandas.DataFrame(kpca(X_tr,2,30))[0:3000]\n",
    "X_test_3 = pandas.DataFrame(kpca(X_tr,2,30))[3000:5000]\n",
    "Y_train_3 = y_train[0:3000]\n",
    "Y_test_3 = y_train[3000:5000]\n",
    "print(X_train_3.shape)\n",
    "print(X_test_3.shape)\n",
    "Y_train_3[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict_OvR=SVMOvR(X_train_3,X_test_3,Y_train_3,6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compt=Y_test_3.values[:,0]-y_predict_OvR\n",
    "print(\"Pourcentage de bonnes prédictions :\",sum(compt==0)/len(Y_test_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On soumet nos résultats finaux sur le site Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le modèle optimal est un SVM One Vs Rest (paramètres C=6 et sigma=2) après HOG mais sans ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe : 0\n",
      "Taille de la matrice de Gram : (5000, 5000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ce6ae46513cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVMOvR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-8dd18e7b5237>\u001b[0m in \u001b[0;36mSVMOvR\u001b[0;34m(data_train, data_test, is_train, C, sigma)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mis_train_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0ms1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mSVMPred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0masfarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_train_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0ms2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Temps pour l'entrainement :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c219c5f874a4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mlagrange_multipliers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_multipliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlagrange_multipliers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c219c5f874a4>\u001b[0m in \u001b[0;36m_compute_multipliers\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcvxopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcvxopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvxopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolvers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mqp\u001b[0;34m(P, q, G, h, A, b, solver, kktsolver, initvals, **kwargs)\u001b[0m\n\u001b[1;32m   4468\u001b[0m             'residual as dual infeasibility certificate': dinfres} \n\u001b[1;32m   4469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4470\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconeqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkktsolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[0;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[1;32m   2063\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrti\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rti'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2066\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mArithmeticError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rank(A) < p or Rank([P; A; G]) < n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mkktsolver\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m   1979\u001b[0m              \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkkt_chol2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m          \u001b[0;32mdef\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1981\u001b[0;31m              \u001b[0;32mreturn\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxnewcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxnewcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/cvxopt/misc.py\u001b[0m in \u001b[0;36mfactor\u001b[0;34m(W, H, Df)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'firstcall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m             \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyrk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'T'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmnl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m                 \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyrk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dfs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'T'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_pred=SVMOvR(X_tr,X_te,y_train,6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [int(i) for i in final_pred]\n",
    "X_result = pandas.DataFrame(results,columns=['Prediction'])\n",
    "X_result.index += 1\n",
    "X_result.to_csv('Yte.csv',index=True,index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
