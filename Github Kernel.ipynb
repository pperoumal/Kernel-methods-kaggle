{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet du cours \"Kernel methods\" du master MVA\n",
    "Le projet de ce cours consiste en la classification d'images. Dans ce notebook, on implémente de manière la plus détaillée et la plus claire possible l'ensemble des classes et fonctions des algorithmes que nous utilisons.    \n",
    "\n",
    "Ce projet se fera en 3 étapes :\n",
    "- Preprocessing des données\n",
    "- Feature extraction\n",
    "- Prediction par SVM\n",
    "\n",
    "Il est indiqué dans l'énoncé que l'étape de preprocessing a déjà été réalisée. Nous allons donc directement procéder à l'extraction de nos features (par HOG) et à la prédiction de la nature de nos images (par SVM).\n",
    "\n",
    "Ce notebook utilise comme kernel le RBF kernel qui est celui qui donne les meilleurs résultats. Pour voir les implémentations réalisées avec d'autres kernels, on pourra se reporter aux notebooks joints (moins détaillés et n'effectuant pas toutes les étapes ci-dessous mais présentant notamment les implémentations liées à chaque kernel considéré)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas\n",
    "import cvxopt\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "from scipy.stats import mode\n",
    "from scipy.linalg import eigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données\n",
    "\n",
    "On importe les données du concours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train=pandas.read_csv('/Users/badr-eddinecherief-abdellatif/Documents/ENSAE/3A/MVA/Kernel methods/Projet ENS/Bases/Xtr.csv',header=None,sep=',')\n",
    "df_train=df_train.drop(3072,1)\n",
    "df_test=pandas.read_csv('/Users/badr-eddinecherief-abdellatif/Documents/ENSAE/3A/MVA/Kernel methods/Projet ENS/Bases/Xte.csv',header=None,sep=',')\n",
    "df_test=df_test.drop(3072,1)\n",
    "y_train=pandas.read_csv('/Users/badr-eddinecherief-abdellatif/Documents/ENSAE/3A/MVA/Kernel methods/Projet ENS/Bases/Ytr.csv',sep=';')\n",
    "y_train=pandas.DataFrame(y_train['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.genfromtxt('/Users/badr-eddinecherief-abdellatif/Documents/ENSAE/3A/MVA/Kernel methods/Projet ENS/Bases/Xtr.csv',delimiter=',')[:,0:3072]\n",
    "Y_train = np.genfromtxt('/Users/badr-eddinecherief-abdellatif/Documents/ENSAE/3A/MVA/Kernel methods/Projet ENS/Bases/Ytr.csv',delimiter=';')[1:5001,1]\n",
    "X_test = np.genfromtxt('/Users/badr-eddinecherief-abdellatif/Documents/ENSAE/3A/MVA/Kernel methods/Projet ENS/Bases/Xte.csv',delimiter=',')[:,0:3072]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Répartition des labels\n",
    "Nous travaillons sur un échantillon d'apprentissage dans le but de classifier des images. Vérifions que nous avons bien équirépartition des images dans l'échantillon d'apprentissage afin de pouvoir mener à bien notre modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    500\n",
       "3    500\n",
       "6    500\n",
       "2    500\n",
       "9    500\n",
       "5    500\n",
       "1    500\n",
       "8    500\n",
       "4    500\n",
       "0    500\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation des méthodes\n",
    "\n",
    "Dans cette partie, nous implémenterons les différentes méthodes que nous testerons par la suite. Il s'agit des méthodes suivantes:\n",
    "- SVM\n",
    "- ACP\n",
    "- HOG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVMTrainer(object):\n",
    "    def __init__(self, c, sigma):\n",
    "        self._c = c\n",
    "        self.sigma=sigma\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        lagrange_multipliers = self._compute_multipliers(X, y)\n",
    "        return self._construct_predictor(X, y, lagrange_multipliers)\n",
    "\n",
    "    def _gram_matrix(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        v=norm(X,2,axis=1)**2\n",
    "        v2=array([v,]*n_samples)+array([v,]*n_samples).transpose()-2*dot(X.values,transpose(X.values))\n",
    "        K=exp(-v2/(2*(self.sigma)**2)) \n",
    "        print(\"Taille de la matrice de Gram :\",K.shape)\n",
    "        return K\n",
    "\n",
    "    def _construct_predictor(self, X, y, lagrange_multipliers):\n",
    "        support_vector_indices=abs(lagrange_multipliers)>0\n",
    "        support_multipliers = lagrange_multipliers[support_vector_indices] # alpha i non nuls\n",
    "        support_vectors = X[support_vector_indices] # vecteurs supports\n",
    "        support_vector_labels = y[support_vector_indices] # labels des vecteurs supports\n",
    "        print(\"Nombre de vecteurs supports :\",len(support_vectors))\n",
    "        pre=SVMPredictor(sigma=self.sigma,bias=0.0,weights=support_multipliers,\n",
    "             support_vectors=support_vectors,support_vector_labels=support_vector_labels).predictest(support_vectors.values)[0]\n",
    "        bias = np.mean(support_vector_labels[:,0]-pre)\n",
    "        print(\"Biais:\",bias)\n",
    "        return SVMPredictor(sigma=self.sigma,bias=bias,weights=support_multipliers,support_vectors=support_vectors,\n",
    "            support_vector_labels=support_vector_labels)\n",
    "\n",
    "    def _compute_multipliers(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        K=self._gram_matrix(X)\n",
    "        P=cvxopt.matrix(K)\n",
    "        q=cvxopt.matrix(-1*y[:,0])\n",
    "        G_std=cvxopt.matrix(-1*np.diag(y[:,0]))\n",
    "        h_std=cvxopt.matrix(np.zeros(n_samples))\n",
    "        G_slack=cvxopt.matrix(np.diag(y[:,0]))\n",
    "        h_slack=cvxopt.matrix(np.ones(n_samples) * self._c)\n",
    "        G=cvxopt.matrix(np.vstack((G_std, G_slack)))\n",
    "        h=cvxopt.matrix(np.vstack((h_std, h_slack)))\n",
    "        A=cvxopt.matrix(np.ones(n_samples),(1,n_samples))\n",
    "        b=cvxopt.matrix(0.0)\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A=None, b=None)\n",
    "        return np.ravel(solution['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVMPredictor(object):\n",
    "    def __init__(self,sigma,bias,weights,support_vectors,support_vector_labels):\n",
    "        self.sigma=sigma\n",
    "        self._bias = bias\n",
    "        self._weights = weights\n",
    "        self._support_vectors = support_vectors\n",
    "        self._support_vector_labels = support_vector_labels\n",
    "\n",
    "    def predictest(self,x):\n",
    "        v = array([norm(x,2,axis=1)**2,]*len(self._support_vectors))\n",
    "        inter = array([norm(self._support_vectors,2,axis=1)**2,]*len(x)).transpose() + v\n",
    "        inter1 = inter - 2*dot(self._support_vectors,transpose(x))\n",
    "        inter2 = exp(-asarray(inter1)/(2*(self.sigma)**2))\n",
    "        result = dot(transpose(self._weights),inter2)+self._bias\n",
    "        return sign(result),result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation du SVM au cas multi-classe\n",
    "On va tout d'abord implémenter la méthode One Vs One, i.e. considérer 10x9/2=45 problèmes de classifications binaires en traitant des paires d'instances, puis implémenter la méthode One Vs Rest, i.e. entraîner un classifieur par classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Vs One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVMOvO(data_train,data_test,is_train,C,sigma):\n",
    "    SVM=SVMTrainer(C,sigma)\n",
    "    result=(20*ones(len(data_test))).reshape(len(data_test),1)\n",
    "    for i in [0,1,2,3,4,5,6,7,8]:\n",
    "        for j in range(i+1,10):\n",
    "            print(\"Classe :\",i,j)\n",
    "            df_train_ij=data_train[asmatrix(is_train,dtype=ndarray)==(i,j)].copy()\n",
    "            is_train_ij=is_train[asmatrix(is_train,dtype=ndarray)==(i,j)].copy()\n",
    "            is_train_ij[is_train==i]=1\n",
    "            is_train_ij[is_train==j]=-1\n",
    "            s1=time.clock()\n",
    "            SVMPred=SVM.train(df_train_ij,asfarray(is_train_ij))\n",
    "            s2=time.clock()\n",
    "            print(\"Temps pour l'entrainement :\",s2-s1)\n",
    "            s3=time.clock()\n",
    "            values=SVMPred.predictest(data_test.values)[0]\n",
    "            s4=time.clock()\n",
    "            print(\"Temps pour la prédiction :\",s4-s3)\n",
    "            values[values==1]=i\n",
    "            values[values==-1]=j\n",
    "            values=values.reshape(len(data_test),1)\n",
    "            result=concatenate((result,values),1)\n",
    "            is_test_predict=mode(result,axis=1)\n",
    "    return(is_test_predict)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Vs Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVMOvR(data_train,data_test,is_train,C,sigma):\n",
    "    SVM=SVMTrainer(C,sigma)\n",
    "    result=(-20*ones(len(data_test))).reshape(len(data_test),1)\n",
    "    for i in [0,1,2,3,4,5,6,7,8,9]:\n",
    "        print(\"Classe :\",i)\n",
    "        is_train_i=is_train.copy()\n",
    "        is_train_i[is_train==i]=1\n",
    "        is_train_i[is_train!=i]=-1\n",
    "        s1=time.clock()\n",
    "        SVMPred=SVM.train(data_train,asfarray(is_train_i))\n",
    "        s2=time.clock()\n",
    "        print(\"Temps pour l'entrainement :\",s2-s1)\n",
    "        s3=time.clock()\n",
    "        values=SVMPred.predictest(data_test.values)[1]\n",
    "        s4=time.clock()\n",
    "        print(\"Temps pour la prédiction :\",s4-s3)\n",
    "        values=values.reshape(len(data_test),1)\n",
    "        result=concatenate((result,values),1)\n",
    "    predict=argmax(result,axis=1)-1\n",
    "    return(predict)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOG\n",
    "\n",
    "Implémentation de la méthode d'extraction de features inspirée de l'article https://hal.inria.fr/inria-00548512/document de N. Dalal et B. Triggs et du site http://www.learnopencv.com/histogram-of-oriented-gradients/. On choisit de diviser l'image de 32 pixels en 4 cellules de (8,8) pixels chacun, en normalisant par blocs de 4 cellules, ce qui donne une base X de taille 3 (nombre de blocs sur l'axe x) fois 3 (nombre de blocs sur l'axe y) fois 9 (taille d'un histogramme) fois 4 (nombre d'histogrammes par bloc, un histogramme correspondant à une cellule) fois 3 (pour les différentes couleurs de l'image), i.e. on obtient une base X avec 972 variables au lieu de 3072."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HOG :\n",
    "\n",
    "    def __init__(self, nbins=9):\n",
    "        self.nbins = nbins\n",
    "\n",
    "    def _calc_gradient_discret(self, img):\n",
    "        n_x, n_y = img.shape\n",
    "        histogram = numpy.zeros((4, 4, self.nbins))\n",
    "\n",
    "        for i in range(0, n_x) :\n",
    "            for j in range(0, n_y) :\n",
    "                dx = 0\n",
    "                dy = 0\n",
    "                if i < n_x - 1 :\n",
    "                    dx += img[i + 1, j]\n",
    "                if i > 0 :\n",
    "                    dx -= img[i - 1, j]\n",
    "                if j < n_y - 1 :\n",
    "                    dy += img[i, j + 1]\n",
    "                if j > 0 :\n",
    "                    dy -= img[i, j - 1]\n",
    "\n",
    "                if dy == 0 and dx == 0 :\n",
    "                    continue\n",
    "\n",
    "                magnitude = numpy.sqrt(dx**2 + dy**2)\n",
    "                if dx == 0 :\n",
    "                    angle = numpy.pi / 2\n",
    "                else:\n",
    "                    angle = numpy.arctan(dy / dx)\n",
    "                    angle = (angle + numpy.pi / 2) / (numpy.pi / self.nbins)\n",
    "               \n",
    "                bin_pos = int(numpy.floor(angle))\n",
    "\n",
    "                if bin_pos == self.nbins :\n",
    "                    bin_pos = 0\n",
    "                    angle = 0\n",
    "\n",
    "                closest_bin = bin_pos\n",
    "\n",
    "                if bin_pos == 0 :\n",
    "                    if angle < 0.5 :\n",
    "                        second_closest_bin = self.nbins - 1\n",
    "                    else:\n",
    "                        second_closest_bin = 1\n",
    "                elif bin_pos == self.nbins - 1 :\n",
    "                    if angle < self.nbins - 0.5 :\n",
    "                        second_closest_bin = self.nbins - 2\n",
    "                    else:\n",
    "                        second_closest_bin = 0\n",
    "                else:\n",
    "                    if angle < bin_pos + 0.5 :\n",
    "                        second_closest_bin = bin_pos - 1\n",
    "                    else:\n",
    "                        second_closest_bin = bin_pos + 1\n",
    "\n",
    "                if angle < bin_pos + 0.5 :\n",
    "                    second_closest_bin_distance = angle - (bin_pos - 0.5)\n",
    "                else:\n",
    "                    second_closest_bin_distance = (bin_pos + 1.5) - angle\n",
    "\n",
    "                r = second_closest_bin_distance\n",
    "                histogram[i / 8, j / 8, closest_bin] += r * magnitude\n",
    "                histogram[i / 8, j / 8, second_closest_bin] += (1 - r) * magnitude\n",
    "\n",
    "        vec = numpy.zeros((3, 3, self.nbins * 4))\n",
    "\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                aux = histogram[i:i + 2, j:j + 2, :].flatten().copy()\n",
    "                aux = aux / numpy.linalg.norm(aux)\n",
    "                vec[i, j, :] = aux\n",
    "\n",
    "        return vec.flatten()\n",
    "\n",
    "    \n",
    "    def _calc_gradient_one_image(self, img):\n",
    "        nchannels = img.shape[2]\n",
    "        vec = []\n",
    "\n",
    "        for i in range(nchannels):\n",
    "            vec.append(self._calc_gradient_discret(img[:,:,i]))\n",
    "\n",
    "        return numpy.array(vec).flatten()\n",
    "\n",
    "    \n",
    "    def hog(self, X):\n",
    "        n = X.shape[0]\n",
    "        X_new = []\n",
    "\n",
    "        for i in range(n):\n",
    "            X_new.append(self._calc_gradient_one_image(X[i,:,:,:]))\n",
    "\n",
    "        return numpy.array(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "Afin de tester nos modèles sur nos données d'entraînement, on va découper notre base d'entraînement en train/test à hauteur de 60/40%.\n",
    "\n",
    "Pour plus de clarté, on ne présente ici que le modèle final. Se reporter aux autres notebooks pour plus de détails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Après HOG :  SVM One Vs Rest (C=1, sigma=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:63: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:64: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# Création de la nouvelle base X obtenue après extraction de features\n",
    "\n",
    "Xtrain = numpy.reshape(X_train, (X_train.shape[0], 3, 32, 32))\n",
    "Xtrain = numpy.swapaxes(Xtrain, 1, 2)\n",
    "Xtrain = numpy.swapaxes(Xtrain, 2, 3)\n",
    "\n",
    "Xtest = numpy.reshape(X_test, (X_test.shape[0], 3, 32, 32))\n",
    "Xtest = numpy.swapaxes(Xtest, 1, 2)\n",
    "Xtest = numpy.swapaxes(Xtest, 2, 3)\n",
    "\n",
    "histogram=HOG(nbins=9)\n",
    "h=histogram.hog(Xtrain)\n",
    "g=histogram.hog(Xtest)\n",
    "\n",
    "X_tr = pandas.DataFrame(h)\n",
    "X_te = pandas.DataFrame(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 972)\n",
      "(2000, 972)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    311\n",
       "1    308\n",
       "0    306\n",
       "6    305\n",
       "8    304\n",
       "4    298\n",
       "5    294\n",
       "7    292\n",
       "9    291\n",
       "2    291\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2 = X_tr[0:3000]\n",
    "X_test_2 = X_tr[3000:5000]\n",
    "Y_train_2 = y_train[0:3000]\n",
    "Y_test_2 = y_train[3000:5000]\n",
    "print(X_train_2.shape)\n",
    "print(X_test_2.shape)\n",
    "Y_train_2[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe : 0\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.1590e+02 -5.3848e+03  2e+04  2e+00  2e-15\n",
      " 1: -3.4990e+02 -2.9285e+03  4e+03  2e-01  2e-15\n",
      " 2: -3.3254e+02 -8.3656e+02  6e+02  2e-02  3e-15\n",
      " 3: -3.6704e+02 -5.1380e+02  2e+02  5e-03  2e-15\n",
      " 4: -3.8693e+02 -4.2974e+02  4e+01  1e-03  2e-15\n",
      " 5: -3.9489e+02 -4.0666e+02  1e+01  5e-05  2e-15\n",
      " 6: -3.9776e+02 -3.9985e+02  2e+00  4e-06  2e-15\n",
      " 7: -3.9840e+02 -3.9862e+02  2e-01  3e-07  2e-15\n",
      " 8: -3.9848e+02 -3.9849e+02  7e-03  5e-09  2e-15\n",
      " 9: -3.9849e+02 -3.9849e+02  2e-04  9e-11  2e-15\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.046\n",
      "Temps pour l'entrainement : 43.387455000000045\n",
      "Temps pour la prédiction : 1.0714130000000068\n",
      "Classe : 1\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0098e+02 -5.6251e+03  3e+04  2e+00  3e-15\n",
      " 1: -3.3132e+02 -3.1783e+03  4e+03  2e-01  3e-15\n",
      " 2: -3.1044e+02 -8.8245e+02  7e+02  3e-02  3e-15\n",
      " 3: -3.5316e+02 -5.3742e+02  2e+02  5e-03  3e-15\n",
      " 4: -3.7840e+02 -4.3482e+02  6e+01  1e-03  3e-15\n",
      " 5: -3.8923e+02 -4.0353e+02  1e+01  7e-05  4e-15\n",
      " 6: -3.9268e+02 -3.9556e+02  3e+00  6e-06  4e-15\n",
      " 7: -3.9356e+02 -3.9382e+02  3e-01  2e-07  4e-15\n",
      " 8: -3.9365e+02 -3.9366e+02  9e-03  6e-09  4e-15\n",
      " 9: -3.9366e+02 -3.9366e+02  2e-04  1e-10  4e-15\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.0333333333333\n",
      "Temps pour l'entrainement : 50.489911000000006\n",
      "Temps pour la prédiction : 0.9421989999999596\n",
      "Classe : 2\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.9497e+02 -5.9481e+03  3e+04  2e+00  4e-15\n",
      " 1: -4.0349e+02 -3.3526e+03  4e+03  2e-01  5e-15\n",
      " 2: -3.9414e+02 -1.0266e+03  7e+02  3e-02  4e-15\n",
      " 3: -4.2155e+02 -6.2915e+02  2e+02  7e-03  4e-15\n",
      " 4: -4.3931e+02 -4.8983e+02  5e+01  2e-04  4e-15\n",
      " 5: -4.4591e+02 -4.5986e+02  1e+01  4e-05  4e-15\n",
      " 6: -4.4831e+02 -4.5163e+02  3e+00  2e-16  4e-15\n",
      " 7: -4.4902e+02 -4.4958e+02  6e-01  2e-16  4e-15\n",
      " 8: -4.4917e+02 -4.4921e+02  4e-02  2e-16  4e-15\n",
      " 9: -4.4918e+02 -4.4918e+02  1e-03  2e-16  4e-15\n",
      "10: -4.4918e+02 -4.4918e+02  2e-05  2e-16  5e-15\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.102666666667\n",
      "Temps pour l'entrainement : 52.88592899999992\n",
      "Temps pour la prédiction : 0.9140899999999874\n",
      "Classe : 3\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.4932e+02 -6.3975e+03  3e+04  3e+00  3e-15\n",
      " 1: -4.4303e+02 -3.7442e+03  5e+03  2e-01  3e-15\n",
      " 2: -4.3852e+02 -1.1507e+03  8e+02  3e-02  3e-15\n",
      " 3: -4.7036e+02 -6.6604e+02  2e+02  5e-03  3e-15\n",
      " 4: -4.8790e+02 -5.4339e+02  6e+01  6e-04  3e-15\n",
      " 5: -4.9462e+02 -5.0749e+02  1e+01  3e-05  3e-15\n",
      " 6: -4.9657e+02 -5.0073e+02  4e+00  1e-16  3e-15\n",
      " 7: -4.9736e+02 -4.9799e+02  6e-01  2e-16  3e-15\n",
      " 8: -4.9751e+02 -4.9755e+02  3e-02  2e-16  3e-15\n",
      " 9: -4.9752e+02 -4.9753e+02  1e-03  2e-16  4e-15\n",
      "10: -4.9753e+02 -4.9753e+02  3e-05  2e-16  3e-15\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.138\n",
      "Temps pour l'entrainement : 48.51735600000006\n",
      "Temps pour la prédiction : 0.9013460000001032\n",
      "Classe : 4\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.1886e+02 -5.4243e+03  2e+04  2e+00  3e-15\n",
      " 1: -4.1684e+02 -2.9541e+03  3e+03  1e-01  4e-15\n",
      " 2: -4.2507e+02 -1.0663e+03  7e+02  3e-02  3e-15\n",
      " 3: -4.6075e+02 -6.2863e+02  2e+02  5e-03  3e-15\n",
      " 4: -4.7775e+02 -5.1848e+02  4e+01  6e-04  3e-15\n",
      " 5: -4.8339e+02 -4.9420e+02  1e+01  9e-05  3e-15\n",
      " 6: -4.8549e+02 -4.8730e+02  2e+00  3e-06  3e-15\n",
      " 7: -4.8596e+02 -4.8613e+02  2e-01  1e-07  3e-15\n",
      " 8: -4.8601e+02 -4.8602e+02  5e-03  3e-09  3e-15\n",
      " 9: -4.8601e+02 -4.8601e+02  1e-04  5e-11  4e-15\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.139333333333\n",
      "Temps pour l'entrainement : 44.488603999999896\n",
      "Temps pour la prédiction : 0.9137809999999718\n",
      "Classe : 5\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.8156e+02 -5.8916e+03  3e+04  2e+00  3e-15\n",
      " 1: -3.9043e+02 -3.3213e+03  4e+03  2e-01  4e-15\n",
      " 2: -3.8294e+02 -9.7794e+02  7e+02  3e-02  4e-15\n",
      " 3: -4.2037e+02 -6.0392e+02  2e+02  5e-03  4e-15\n",
      " 4: -4.4035e+02 -4.9473e+02  6e+01  7e-04  4e-15\n",
      " 5: -4.4810e+02 -4.6320e+02  2e+01  1e-04  4e-15\n",
      " 6: -4.5080e+02 -4.5510e+02  4e+00  2e-05  4e-15\n",
      " 7: -4.5182e+02 -4.5244e+02  6e-01  6e-07  4e-15\n",
      " 8: -4.5201e+02 -4.5205e+02  4e-02  1e-08  4e-15\n",
      " 9: -4.5202e+02 -4.5202e+02  8e-04  3e-10  4e-15\n",
      "10: -4.5202e+02 -4.5202e+02  2e-05  4e-12  4e-15\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.0986666666667\n",
      "Temps pour l'entrainement : 48.86681899999985\n",
      "Temps pour la prédiction : 0.9391120000000228\n",
      "Classe : 6\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.8968e+02 -5.5453e+03  2e+04  2e+00  3e-15\n",
      " 1: -3.9766e+02 -3.0406e+03  4e+03  1e-01  4e-15\n",
      " 2: -4.0540e+02 -1.0478e+03  7e+02  3e-02  3e-15\n",
      " 3: -4.4388e+02 -6.1572e+02  2e+02  3e-03  3e-15\n",
      " 4: -4.6325e+02 -5.1853e+02  6e+01  6e-04  3e-15\n",
      " 5: -4.7131e+02 -4.8413e+02  1e+01  4e-05  3e-15\n",
      " 6: -4.7387e+02 -4.7652e+02  3e+00  4e-06  3e-15\n",
      " 7: -4.7455e+02 -4.7485e+02  3e-01  2e-16  3e-15\n",
      " 8: -4.7465e+02 -4.7466e+02  2e-02  2e-16  3e-15\n",
      " 9: -4.7465e+02 -4.7465e+02  3e-04  2e-16  3e-15\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.0973333333333\n",
      "Temps pour l'entrainement : 44.57135999999991\n",
      "Temps pour la prédiction : 0.8985000000000127\n",
      "Classe : 7\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2720e+02 -6.1962e+03  3e+04  3e+00  3e-15\n",
      " 1: -3.4213e+02 -3.5726e+03  5e+03  2e-01  3e-15\n",
      " 2: -3.3225e+02 -1.0469e+03  8e+02  3e-02  3e-15\n",
      " 3: -3.6907e+02 -5.9247e+02  2e+02  7e-03  3e-15\n",
      " 4: -3.9315e+02 -4.5682e+02  6e+01  1e-03  3e-15\n",
      " 5: -4.0300e+02 -4.1937e+02  2e+01  1e-04  3e-15\n",
      " 6: -4.0649e+02 -4.0955e+02  3e+00  2e-16  3e-15\n",
      " 7: -4.0730e+02 -4.0779e+02  5e-01  2e-16  3e-15\n",
      " 8: -4.0746e+02 -4.0748e+02  2e-02  2e-16  3e-15\n",
      " 9: -4.0746e+02 -4.0746e+02  5e-04  2e-16  3e-15\n",
      "10: -4.0746e+02 -4.0746e+02  1e-05  2e-16  3e-15\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.0673333333333\n",
      "Temps pour l'entrainement : 46.6394499999999\n",
      "Temps pour la prédiction : 0.9025639999999839\n",
      "Classe : 8\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9346e+02 -5.5404e+03  3e+04  2e+00  3e-15\n",
      " 1: -3.2670e+02 -3.0220e+03  4e+03  2e-01  4e-15\n",
      " 2: -3.1765e+02 -8.5602e+02  6e+02  3e-02  4e-15\n",
      " 3: -3.5336e+02 -5.3028e+02  2e+02  6e-03  4e-15\n",
      " 4: -3.7592e+02 -4.2659e+02  5e+01  6e-04  4e-15\n",
      " 5: -3.8423e+02 -4.0164e+02  2e+01  2e-16  4e-15\n",
      " 6: -3.8769e+02 -3.9221e+02  5e+00  2e-16  4e-15\n",
      " 7: -3.8885e+02 -3.8964e+02  8e-01  2e-16  4e-15\n",
      " 8: -3.8912e+02 -3.8917e+02  5e-02  2e-16  4e-15\n",
      " 9: -3.8913e+02 -3.8914e+02  1e-03  2e-16  4e-15\n",
      "10: -3.8913e+02 -3.8913e+02  2e-05  2e-16  4e-15\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.0386666666667\n",
      "Temps pour l'entrainement : 46.553560999999945\n",
      "Temps pour la prédiction : 0.9122319999999036\n",
      "Classe : 9\n",
      "Taille de la matrice de Gram : (3000, 3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8395e+02 -5.7186e+03  3e+04  2e+00  3e-15\n",
      " 1: -3.0724e+02 -3.2371e+03  5e+03  2e-01  3e-15\n",
      " 2: -2.9140e+02 -9.1649e+02  7e+02  3e-02  3e-15\n",
      " 3: -3.3409e+02 -5.4029e+02  2e+02  6e-03  3e-15\n",
      " 4: -3.6114e+02 -4.2163e+02  6e+01  1e-03  3e-15\n",
      " 5: -3.7195e+02 -3.8890e+02  2e+01  2e-04  3e-15\n",
      " 6: -3.7610e+02 -3.7867e+02  3e+00  2e-06  3e-15\n",
      " 7: -3.7692e+02 -3.7713e+02  2e-01  8e-08  3e-15\n",
      " 8: -3.7700e+02 -3.7701e+02  7e-03  3e-09  3e-15\n",
      " 9: -3.7700e+02 -3.7700e+02  2e-04  4e-11  3e-15\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 3000\n",
      "Biais: 0.0453333333333\n",
      "Temps pour l'entrainement : 41.784357999999884\n",
      "Temps pour la prédiction : 0.9172889999999825\n"
     ]
    }
   ],
   "source": [
    "y_predict_OvR=SVMOvR(X_train_2,X_test_2,Y_train_2,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de bonnes prédictions : 0.5625\n"
     ]
    }
   ],
   "source": [
    "compt=Y_test_2.values[:,0]-y_predict_OvR\n",
    "print(\"Pourcentage de bonnes prédictions :\",sum(compt==0)/len(Y_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de bonnes prédictions : 0.3785\n"
     ]
    }
   ],
   "source": [
    "compt=Y_test_3.values[:,0]-y_predict_OvR\n",
    "print(\"Pourcentage de bonnes prédictions :\",sum(compt==0)/len(Y_test_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On soumet nos résultats finaux sur le site Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le modèle optimal est un SVM One Vs Rest (paramètres C=1 et sigma=2) après HOG mais sans ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe : 0\n",
      "Taille de la matrice de Gram : (5000, 5000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.8483e+02 -8.3378e+04  2e+05  5e-01  1e-14\n",
      " 1:  3.2853e+02 -2.1738e+04  3e+04  5e-02  1e-14\n",
      " 2: -2.5897e+02 -5.7085e+03  6e+03  9e-03  1e-14\n",
      " 3: -6.4948e+02 -2.6656e+03  2e+03  2e-03  9e-15\n",
      " 4: -7.9547e+02 -1.6355e+03  8e+02  3e-04  9e-15\n",
      " 5: -8.6431e+02 -1.1129e+03  2e+02  2e-16  9e-15\n",
      " 6: -8.9280e+02 -9.6193e+02  7e+01  2e-16  9e-15\n",
      " 7: -9.0331e+02 -9.1961e+02  2e+01  2e-16  9e-15\n",
      " 8: -9.0677e+02 -9.0849e+02  2e+00  2e-16  9e-15\n",
      " 9: -9.0724e+02 -9.0731e+02  6e-02  2e-16  9e-15\n",
      "10: -9.0726e+02 -9.0726e+02  2e-03  2e-16  9e-15\n",
      "11: -9.0726e+02 -9.0726e+02  5e-05  2e-16  9e-15\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 5000\n",
      "Biais: 0.0\n",
      "Temps pour l'entrainement : 229.1030400000002\n",
      "Temps pour la prédiction : 1.4648799999999937\n",
      "Classe : 1\n",
      "Taille de la matrice de Gram : (5000, 5000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  6.2078e+02 -8.9389e+04  2e+05  5e-01  1e-14\n",
      " 1:  9.1597e+02 -2.4179e+04  3e+04  6e-02  1e-14\n",
      " 2:  1.5214e+01 -6.8716e+03  8e+03  1e-02  1e-14\n",
      " 3: -5.0641e+02 -2.8195e+03  2e+03  3e-03  1e-14\n",
      " 4: -6.9533e+02 -1.5911e+03  9e+02  4e-04  1e-14\n",
      " 5: -7.7523e+02 -1.0661e+03  3e+02  4e-05  1e-14\n",
      " 6: -8.0968e+02 -8.9649e+02  9e+01  5e-06  1e-14\n",
      " 7: -8.2304e+02 -8.4621e+02  2e+01  1e-06  1e-14\n",
      " 8: -8.2779e+02 -8.3142e+02  4e+00  2e-08  1e-14\n",
      " 9: -8.2876e+02 -8.2899e+02  2e-01  7e-10  1e-14\n",
      "10: -8.2883e+02 -8.2884e+02  4e-03  1e-11  1e-14\n",
      "11: -8.2883e+02 -8.2883e+02  8e-05  2e-13  1e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 5000\n",
      "Biais: 0.0\n",
      "Temps pour l'entrainement : 233.27553999999986\n",
      "Temps pour la prédiction : 1.4699929999999313\n",
      "Classe : 2\n",
      "Taille de la matrice de Gram : (5000, 5000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1040e+02 -9.1469e+04  2e+05  5e-01  2e-14\n",
      " 1:  1.8878e+02 -2.4507e+04  3e+04  4e-02  2e-14\n",
      " 2: -4.9038e+02 -7.5252e+03  8e+03  9e-03  2e-14\n",
      " 3: -9.3458e+02 -3.2201e+03  2e+03  2e-03  1e-14\n",
      " 4: -1.0887e+03 -1.9150e+03  8e+02  3e-04  1e-14\n",
      " 5: -1.1473e+03 -1.4325e+03  3e+02  2e-16  1e-14\n",
      " 6: -1.1728e+03 -1.2534e+03  8e+01  2e-16  1e-14\n",
      " 7: -1.1829e+03 -1.2019e+03  2e+01  2e-16  1e-14\n",
      " 8: -1.1863e+03 -1.1881e+03  2e+00  2e-16  1e-14\n",
      " 9: -1.1868e+03 -1.1869e+03  1e-01  2e-16  1e-14\n",
      "10: -1.1868e+03 -1.1868e+03  2e-03  2e-16  1e-14\n",
      "11: -1.1868e+03 -1.1868e+03  6e-05  2e-16  1e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 5000\n",
      "Biais: 0.0\n",
      "Temps pour l'entrainement : 222.080602\n",
      "Temps pour la prédiction : 1.2308760000000802\n",
      "Classe : 3\n",
      "Taille de la matrice de Gram : (5000, 5000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.3408e+02 -9.7179e+04  2e+05  5e-01  2e-14\n",
      " 1:  1.7087e+02 -2.6159e+04  3e+04  4e-02  2e-14\n",
      " 2: -6.2581e+02 -7.4513e+03  7e+03  8e-03  2e-14\n",
      " 3: -1.0939e+03 -3.3517e+03  2e+03  2e-03  2e-14\n",
      " 4: -1.2564e+03 -1.9337e+03  7e+02  2e-04  2e-14\n",
      " 5: -1.3106e+03 -1.4866e+03  2e+02  1e-05  2e-14\n",
      " 6: -1.3283e+03 -1.3812e+03  5e+01  3e-06  2e-14\n",
      " 7: -1.3349e+03 -1.3483e+03  1e+01  3e-07  2e-14\n",
      " 8: -1.3369e+03 -1.3394e+03  3e+00  4e-08  2e-14\n",
      " 9: -1.3373e+03 -1.3376e+03  3e-01  3e-09  2e-14\n",
      "10: -1.3374e+03 -1.3374e+03  1e-02  9e-11  2e-14\n",
      "11: -1.3374e+03 -1.3374e+03  2e-04  1e-12  2e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 5000\n",
      "Biais: 0.0\n",
      "Temps pour l'entrainement : 232.42311400000017\n",
      "Temps pour la prédiction : 1.1566789999997127\n",
      "Classe : 4\n",
      "Taille de la matrice de Gram : (5000, 5000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.4353e+01 -9.1000e+04  2e+05  5e-01  2e-14\n",
      " 1:  5.0009e+02 -2.2102e+04  3e+04  3e-02  2e-14\n",
      " 2: -5.6929e+02 -6.8701e+03  7e+03  7e-03  2e-14\n",
      " 3: -1.0580e+03 -2.9685e+03  2e+03  1e-03  1e-14\n",
      " 4: -1.2307e+03 -1.6974e+03  5e+02  1e-04  1e-14\n",
      " 5: -1.2848e+03 -1.4064e+03  1e+02  2e-05  1e-14\n",
      " 6: -1.3039e+03 -1.3317e+03  3e+01  2e-06  1e-14\n",
      " 7: -1.3097e+03 -1.3130e+03  3e+00  1e-07  1e-14\n",
      " 8: -1.3106e+03 -1.3107e+03  2e-01  4e-09  1e-14\n",
      " 9: -1.3106e+03 -1.3106e+03  5e-03  9e-11  1e-14\n",
      "10: -1.3106e+03 -1.3106e+03  1e-04  1e-12  1e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 5000\n",
      "Biais: 0.0\n",
      "Temps pour l'entrainement : 202.58775100000003\n",
      "Temps pour la prédiction : 1.2606319999999869\n",
      "Classe : 5\n",
      "Taille de la matrice de Gram : (5000, 5000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0709e+02 -8.9469e+04  2e+05  5e-01  2e-14\n",
      " 1:  1.7356e+02 -2.4443e+04  3e+04  5e-02  2e-14\n",
      " 2: -5.1847e+02 -7.5544e+03  8e+03  1e-02  2e-14\n",
      " 3: -9.4604e+02 -3.2703e+03  2e+03  3e-03  1e-14\n",
      " 4: -1.1122e+03 -1.9423e+03  8e+02  5e-04  1e-14\n",
      " 5: -1.1809e+03 -1.4056e+03  2e+02  2e-05  1e-14\n",
      " 6: -1.2061e+03 -1.2661e+03  6e+01  2e-16  1e-14\n",
      " 7: -1.2148e+03 -1.2275e+03  1e+01  2e-16  1e-14\n",
      " 8: -1.2170e+03 -1.2191e+03  2e+00  2e-16  1e-14\n",
      " 9: -1.2175e+03 -1.2176e+03  7e-02  2e-16  1e-14\n",
      "10: -1.2175e+03 -1.2175e+03  2e-03  2e-16  1e-14\n",
      "11: -1.2175e+03 -1.2175e+03  4e-05  2e-16  1e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 5000\n",
      "Biais: 0.0\n",
      "Temps pour l'entrainement : 228.71153000000004\n",
      "Temps pour la prédiction : 1.2149349999999686\n",
      "Classe : 6\n",
      "Taille de la matrice de Gram : (5000, 5000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.4448e+02 -8.3011e+04  2e+05  4e-01  1e-14\n",
      " 1:  7.8727e+02 -2.0032e+04  3e+04  4e-02  2e-14\n",
      " 2: -3.6473e+02 -5.8481e+03  6e+03  7e-03  2e-14\n",
      " 3: -8.5815e+02 -2.6584e+03  2e+03  1e-03  1e-14\n",
      " 4: -1.0050e+03 -1.7676e+03  8e+02  4e-04  1e-14\n",
      " 5: -1.0831e+03 -1.2778e+03  2e+02  2e-05  1e-14\n",
      " 6: -1.1097e+03 -1.1665e+03  6e+01  5e-06  1e-14\n",
      " 7: -1.1203e+03 -1.1293e+03  9e+00  1e-07  1e-14\n",
      " 8: -1.1224e+03 -1.1235e+03  1e+00  1e-08  1e-14\n",
      " 9: -1.1227e+03 -1.1227e+03  4e-02  3e-10  1e-14\n",
      "10: -1.1227e+03 -1.1227e+03  1e-03  7e-12  1e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 5000\n",
      "Biais: 0.0\n",
      "Temps pour l'entrainement : 200.22688100000005\n",
      "Temps pour la prédiction : 1.1070049999998446\n",
      "Classe : 7\n",
      "Taille de la matrice de Gram : (5000, 5000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.7457e+02 -8.6253e+04  2e+05  5e-01  1e-14\n",
      " 1:  7.5936e+02 -2.1117e+04  3e+04  4e-02  2e-14\n",
      " 2: -2.4138e+02 -6.1431e+03  6e+03  7e-03  2e-14\n",
      " 3: -7.2189e+02 -2.7077e+03  2e+03  1e-03  1e-14\n",
      " 4: -8.8853e+02 -1.5579e+03  7e+02  1e-04  1e-14\n",
      " 5: -9.4949e+02 -1.1511e+03  2e+02  2e-05  1e-14\n",
      " 6: -9.7632e+02 -1.0214e+03  5e+01  2e-16  1e-14\n",
      " 7: -9.8392e+02 -9.9433e+02  1e+01  2e-16  1e-14\n",
      " 8: -9.8621e+02 -9.8723e+02  1e+00  2e-16  1e-14\n",
      " 9: -9.8649e+02 -9.8653e+02  4e-02  2e-16  1e-14\n",
      "10: -9.8650e+02 -9.8650e+02  1e-03  2e-16  1e-14\n",
      "11: -9.8650e+02 -9.8650e+02  3e-05  2e-16  1e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 5000\n",
      "Biais: 0.0\n",
      "Temps pour l'entrainement : 222.48347000000012\n",
      "Temps pour la prédiction : 1.6490530000000945\n",
      "Classe : 8\n",
      "Taille de la matrice de Gram : (5000, 5000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.1945e+02 -8.4467e+04  2e+05  5e-01  1e-14\n",
      " 1:  4.6999e+02 -2.1564e+04  3e+04  5e-02  2e-14\n",
      " 2: -2.2524e+02 -5.7888e+03  6e+03  9e-03  2e-14\n",
      " 3: -6.4618e+02 -2.4998e+03  2e+03  2e-03  1e-14\n",
      " 4: -8.1074e+02 -1.4065e+03  6e+02  2e-16  1e-14\n",
      " 5: -8.7012e+02 -1.0461e+03  2e+02  2e-16  1e-14\n",
      " 6: -8.9271e+02 -9.4726e+02  5e+01  2e-16  1e-14\n",
      " 7: -9.0200e+02 -9.1226e+02  1e+01  2e-16  1e-14\n",
      " 8: -9.0430e+02 -9.0589e+02  2e+00  2e-16  1e-14\n",
      " 9: -9.0474e+02 -9.0480e+02  6e-02  2e-16  1e-14\n",
      "10: -9.0476e+02 -9.0476e+02  1e-03  2e-16  1e-14\n",
      "11: -9.0476e+02 -9.0476e+02  2e-05  2e-16  1e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 5000\n",
      "Biais: 0.0\n",
      "Temps pour l'entrainement : 228.10168899999962\n",
      "Temps pour la prédiction : 1.3291420000000471\n",
      "Classe : 9\n",
      "Taille de la matrice de Gram : (5000, 5000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  6.0742e+02 -8.7014e+04  2e+05  5e-01  1e-14\n",
      " 1:  1.0427e+03 -2.3630e+04  3e+04  5e-02  2e-14\n",
      " 2:  1.3249e+01 -6.4777e+03  7e+03  1e-02  1e-14\n",
      " 3: -5.1331e+02 -2.8775e+03  2e+03  3e-03  1e-14\n",
      " 4: -6.9704e+02 -1.7210e+03  1e+03  9e-04  9e-15\n",
      " 5: -7.7578e+02 -1.2345e+03  5e+02  2e-04  9e-15\n",
      " 6: -8.0806e+02 -1.0607e+03  3e+02  1e-16  9e-15\n",
      " 7: -8.3804e+02 -9.0099e+02  6e+01  2e-16  9e-15\n",
      " 8: -8.4955e+02 -8.5956e+02  1e+01  2e-16  9e-15\n",
      " 9: -8.5211e+02 -8.5292e+02  8e-01  2e-16  9e-15\n",
      "10: -8.5236e+02 -8.5238e+02  2e-02  2e-16  1e-14\n",
      "11: -8.5237e+02 -8.5237e+02  5e-04  2e-16  1e-14\n",
      "Optimal solution found.\n",
      "Nombre de vecteurs supports : 5000\n",
      "Biais: 0.0\n",
      "Temps pour l'entrainement : 233.35319899999968\n",
      "Temps pour la prédiction : 1.4557180000001608\n"
     ]
    }
   ],
   "source": [
    "final_pred=SVMOvR(X_tr,X_te,y_train,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [int(i) for i in final_pred]\n",
    "X_result = pandas.DataFrame(results,columns=['Prediction'])\n",
    "X_result.index += 1\n",
    "X_result.to_csv('Yte.csv',index=True,index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
